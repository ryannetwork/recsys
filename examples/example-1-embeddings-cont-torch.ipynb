{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.torch_embeds_cont_supervised import ContEmbDataset, ContEmbModel, Calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/result_df.csv', nrows=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col = [\"region\"]\n",
    "cont_col = [col for col in data.columns if 'share' in col]\n",
    "target_col = [\"okved2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/pandas/core/frame.py:4153: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n",
      "/Users/korniltsevdmitry/Desktop/python/projects/recommendation_systems/core/torch_embeds_cont_supervised.py:142: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = label_encoders[col].fit_transform(data[col])\n",
      "/Users/korniltsevdmitry/Desktop/python/projects/recommendation_systems/core/torch_embeds_cont_supervised.py:143: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col] = data[col].astype('category')\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContEmbModel(\n",
      "  (emb_layers): ModuleList(\n",
      "    (0): Embedding(77, 39)\n",
      "  )\n",
      "  (lin1): Linear(in_features=201, out_features=800, bias=True)\n",
      "  (lin2): Linear(in_features=800, out_features=280, bias=True)\n",
      "  (lin3): Linear(in_features=280, out_features=75, bias=True)\n",
      "  (bn1): BatchNorm1d(162, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn3): BatchNorm1d(280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (emb_drop): Dropout(p=0.6, inplace=False)\n",
      "  (drops): Dropout(p=0.3, inplace=False)\n",
      ")\n",
      "weights\n",
      "tensor(-183.8174)\n",
      "weights\n",
      "tensor(-319.5779)\n",
      "weights\n",
      "tensor(-426.6509)\n",
      "weights\n",
      "tensor(-506.7660)\n",
      "weights\n",
      "tensor(-574.2112)\n",
      "weights\n",
      "tensor(-643.7041)\n",
      "training loss:  4.732555830656593\n",
      "3 3\n",
      "valid loss 7.757 and accuracy 0.082\n",
      "weights\n",
      "tensor(-706.4934)\n",
      "weights\n",
      "tensor(-766.1605)\n",
      "weights\n",
      "tensor(-824.3514)\n",
      "weights\n",
      "tensor(-878.4723)\n",
      "weights\n",
      "tensor(-925.4181)\n",
      "weights\n",
      "tensor(-972.6874)\n",
      "training loss:  3.7481512731580593\n",
      "3 3\n",
      "valid loss 4.060 and accuracy 0.267\n",
      "weights\n",
      "tensor(-1015.3682)\n",
      "weights\n",
      "tensor(-1054.3475)\n",
      "weights\n",
      "tensor(-1091.1304)\n",
      "weights\n",
      "tensor(-1124.4493)\n",
      "weights\n",
      "tensor(-1156.6230)\n",
      "weights\n",
      "tensor(-1187.4015)\n",
      "training loss:  3.125757151219382\n",
      "3 3\n",
      "valid loss 3.564 and accuracy 0.274\n",
      "weights\n",
      "tensor(-1216.2731)\n",
      "weights\n",
      "tensor(-1243.0955)\n",
      "weights\n",
      "tensor(-1269.3870)\n",
      "weights\n",
      "tensor(-1295.1752)\n",
      "weights\n",
      "tensor(-1319.1515)\n",
      "weights\n",
      "tensor(-1344.2075)\n",
      "training loss:  2.709937430139798\n",
      "3 3\n",
      "valid loss 3.386 and accuracy 0.262\n",
      "weights\n",
      "tensor(-1366.9293)\n",
      "weights\n",
      "tensor(-1388.0300)\n",
      "weights\n",
      "tensor(-1408.8441)\n",
      "weights\n",
      "tensor(-1428.6018)\n",
      "weights\n",
      "tensor(-1447.8477)\n",
      "weights\n",
      "tensor(-1467.7201)\n",
      "training loss:  2.5032910795354133\n",
      "3 3\n",
      "valid loss 3.323 and accuracy 0.291\n",
      "weights\n",
      "tensor(-1487.6548)\n",
      "weights\n",
      "tensor(-1506.9843)\n",
      "weights\n",
      "tensor(-1525.8090)\n",
      "weights\n",
      "tensor(-1543.3518)\n",
      "weights\n",
      "tensor(-1559.7526)\n",
      "weights\n",
      "tensor(-1575.9049)\n",
      "training loss:  2.3620344439549235\n",
      "3 3\n",
      "valid loss 3.383 and accuracy 0.306\n",
      "weights\n",
      "tensor(-1591.2832)\n",
      "weights\n",
      "tensor(-1605.7102)\n",
      "weights\n",
      "tensor(-1618.5951)\n",
      "weights\n",
      "tensor(-1631.4132)\n",
      "weights\n",
      "tensor(-1643.6591)\n",
      "weights\n",
      "tensor(-1657.3036)\n",
      "training loss:  2.1866812029881264\n",
      "3 3\n",
      "valid loss 3.413 and accuracy 0.279\n",
      "weights\n",
      "tensor(-1670.2534)\n",
      "weights\n",
      "tensor(-1682.8511)\n",
      "weights\n",
      "tensor(-1694.0530)\n",
      "weights\n",
      "tensor(-1704.7430)\n",
      "weights\n",
      "tensor(-1714.4402)\n",
      "weights\n",
      "tensor(-1724.5664)\n",
      "training loss:  2.0812942369660337\n",
      "3 3\n",
      "valid loss 3.489 and accuracy 0.265\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         4\n",
      "           3       0.34      0.48      0.40        33\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.22      0.09      0.12        23\n",
      "           8       0.33      0.14      0.20         7\n",
      "           9       0.00      0.00      0.00         3\n",
      "          10       0.14      0.06      0.08        17\n",
      "          11       0.35      0.55      0.43       188\n",
      "          12       0.46      0.34      0.39        35\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       0.00      0.00      0.00         4\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         7\n",
      "          17       0.00      0.00      0.00         2\n",
      "          18       0.00      0.00      0.00         1\n",
      "          19       0.40      0.22      0.29         9\n",
      "          20       0.00      0.00      0.00         8\n",
      "          21       0.00      0.00      0.00         6\n",
      "          22       0.00      0.00      0.00         1\n",
      "          23       0.00      0.00      0.00         1\n",
      "          24       0.33      0.07      0.12        14\n",
      "          25       0.00      0.00      0.00         1\n",
      "          27       0.00      0.00      0.00         7\n",
      "          28       0.00      0.00      0.00         6\n",
      "          29       0.00      0.00      0.00         1\n",
      "          30       0.00      0.00      0.00         5\n",
      "          31       0.00      0.00      0.00         2\n",
      "          32       0.21      0.39      0.27        51\n",
      "          36       0.00      0.00      0.00         3\n",
      "          37       0.33      0.07      0.12        14\n",
      "          39       0.00      0.00      0.00         3\n",
      "          40       0.00      0.00      0.00         2\n",
      "          41       0.00      0.00      0.00         5\n",
      "          42       0.00      0.00      0.00         3\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.50      0.17      0.25        12\n",
      "          45       0.00      0.00      0.00         5\n",
      "          46       0.00      0.00      0.00        10\n",
      "          47       0.50      0.20      0.29         5\n",
      "          48       0.00      0.00      0.00         1\n",
      "          49       0.22      0.38      0.28        26\n",
      "          50       0.50      0.25      0.33         4\n",
      "          51       0.00      0.00      0.00         3\n",
      "          52       0.00      0.00      0.00        20\n",
      "          53       0.00      0.00      0.00         8\n",
      "          54       0.00      0.00      0.00         1\n",
      "          55       0.00      0.00      0.00         2\n",
      "          56       0.00      0.00      0.00         6\n",
      "          57       0.00      0.00      0.00         6\n",
      "          58       0.00      0.00      0.00        12\n",
      "          59       0.08      0.09      0.08        11\n",
      "          60       0.00      0.00      0.00         1\n",
      "          61       0.00      0.00      0.00         4\n",
      "          62       0.00      0.00      0.00         4\n",
      "          64       0.00      0.00      0.00         4\n",
      "          65       0.00      0.00      0.00         2\n",
      "          67       0.00      0.00      0.00         2\n",
      "          68       0.00      0.00      0.00         5\n",
      "          69       0.00      0.00      0.00        10\n",
      "          71       0.00      0.00      0.00         5\n",
      "          72       0.00      0.00      0.00         3\n",
      "          73       0.00      0.00      0.00         2\n",
      "          74       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.27       660\n",
      "   macro avg       0.07      0.05      0.06       660\n",
      "weighted avg       0.22      0.27      0.22       660\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model_1 = Calculate(data=data, \n",
    "                  target_col=target_col, \n",
    "                  cat_col=cat_col, \n",
    "                  cont_col=cont_col)\n",
    "\n",
    "y_true, y_pred = model_1.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContEmbModel(\n",
      "  (emb_layers): ModuleList(\n",
      "    (0): Embedding(77, 39)\n",
      "  )\n",
      "  (lin1): Linear(in_features=201, out_features=800, bias=True)\n",
      "  (lin2): Linear(in_features=800, out_features=280, bias=True)\n",
      "  (lin3): Linear(in_features=280, out_features=75, bias=True)\n",
      "  (bn1): BatchNorm1d(162, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn3): BatchNorm1d(280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (emb_drop): Dropout(p=0.6, inplace=False)\n",
      "  (drops): Dropout(p=0.3, inplace=False)\n",
      ")\n",
      "weights\n",
      "tensor(-172.9049)\n",
      "weights\n",
      "tensor(-303.6601)\n",
      "weights\n",
      "tensor(-396.3014)\n",
      "weights\n",
      "tensor(-462.0973)\n",
      "weights\n",
      "tensor(-518.4233)\n",
      "weights\n",
      "tensor(-572.2623)\n",
      "weights\n",
      "tensor(-620.1772)\n",
      "weights\n",
      "tensor(-663.8503)\n",
      "training loss:  4.6054630355834965\n",
      "weights\n",
      "tensor(-707.7117)\n",
      "weights\n",
      "tensor(-749.4726)\n",
      "weights\n",
      "tensor(-788.2477)\n",
      "weights\n",
      "tensor(-821.7491)\n",
      "weights\n",
      "tensor(-851.3189)\n",
      "weights\n",
      "tensor(-879.7659)\n",
      "weights\n",
      "tensor(-901.9044)\n",
      "weights\n",
      "tensor(-922.6315)\n",
      "training loss:  3.614063787460327\n",
      "weights\n",
      "tensor(-942.4399)\n",
      "weights\n",
      "tensor(-961.9472)\n",
      "weights\n",
      "tensor(-980.6507)\n",
      "weights\n",
      "tensor(-996.1156)\n",
      "weights\n",
      "tensor(-1010.3309)\n",
      "weights\n",
      "tensor(-1024.3984)\n",
      "weights\n",
      "tensor(-1037.8562)\n",
      "weights\n",
      "tensor(-1052.6853)\n",
      "training loss:  3.032069246292114\n",
      "weights\n",
      "tensor(-1068.0845)\n",
      "weights\n",
      "tensor(-1084.3834)\n",
      "weights\n",
      "tensor(-1099.8680)\n",
      "weights\n",
      "tensor(-1113.9861)\n",
      "weights\n",
      "tensor(-1126.9503)\n",
      "weights\n",
      "tensor(-1140.4856)\n",
      "weights\n",
      "tensor(-1152.8815)\n",
      "weights\n",
      "tensor(-1165.2242)\n",
      "training loss:  2.742169775009155\n",
      "weights\n",
      "tensor(-1176.8313)\n",
      "weights\n",
      "tensor(-1187.9111)\n",
      "weights\n",
      "tensor(-1198.7301)\n",
      "weights\n",
      "tensor(-1209.7588)\n",
      "weights\n",
      "tensor(-1219.7173)\n",
      "weights\n",
      "tensor(-1228.3108)\n",
      "weights\n",
      "tensor(-1236.2598)\n",
      "weights\n",
      "tensor(-1244.0913)\n",
      "training loss:  2.5337280082702636\n",
      "weights\n",
      "tensor(-1252.9760)\n",
      "weights\n",
      "tensor(-1262.3278)\n",
      "weights\n",
      "tensor(-1272.8109)\n",
      "weights\n",
      "tensor(-1283.2943)\n",
      "weights\n",
      "tensor(-1293.2539)\n",
      "weights\n",
      "tensor(-1302.3856)\n",
      "weights\n",
      "tensor(-1310.4698)\n",
      "weights\n",
      "tensor(-1317.7755)\n",
      "training loss:  2.432068567276001\n",
      "weights\n",
      "tensor(-1325.0199)\n",
      "weights\n",
      "tensor(-1333.4655)\n",
      "weights\n",
      "tensor(-1341.9291)\n",
      "weights\n",
      "tensor(-1350.7212)\n",
      "weights\n",
      "tensor(-1359.6697)\n",
      "weights\n",
      "tensor(-1369.1003)\n",
      "weights\n",
      "tensor(-1378.2321)\n",
      "weights\n",
      "tensor(-1385.9243)\n",
      "training loss:  2.2072484264373777\n",
      "weights\n",
      "tensor(-1392.9120)\n",
      "weights\n",
      "tensor(-1400.3986)\n",
      "weights\n",
      "tensor(-1407.9906)\n",
      "weights\n",
      "tensor(-1414.9071)\n",
      "weights\n",
      "tensor(-1421.3877)\n",
      "weights\n",
      "tensor(-1428.8214)\n",
      "weights\n",
      "tensor(-1436.0576)\n",
      "weights\n",
      "tensor(-1442.9592)\n",
      "training loss:  2.153433475494385\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-63a599d50de3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = model_1.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.FloatTensor instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0d947b8d54ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   cont_col=cont_col)\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_no_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/python/projects/recommendation_systems/core/torch_embeds_cont_supervised.py\u001b[0m in \u001b[0;36mevaluate_no_split\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                 \u001b[0;31m# Forward Pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m                 \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcont_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/python/projects/recommendation_systems/core/torch_embeds_cont_supervised.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_cat, x_cont)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_cont\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0memb_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_drop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/python/projects/recommendation_systems/core/torch_embeds_cont_supervised.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_cont\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0memb_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_drop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m         return F.embedding(\n\u001b[1;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1722\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1723\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1724\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.FloatTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "model_2 = Calculate(data=data, \n",
    "                  target_col=target_col, \n",
    "                  cat_col=cat_col, \n",
    "                  cont_col=cont_col)\n",
    "\n",
    "y_pred = model_2.evaluate_no_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
