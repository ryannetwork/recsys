{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pyspark\n",
    "import os\n",
    "import findspark\n",
    "from tqdm import tqdm\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import lit, row_number, col\n",
    "from pyspark.sql.functions import collect_list\n",
    "from pyspark import SparkContext, SparkConf, HiveContext\n",
    "from pyspark.mllib.feature import Word2Vec\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_location = '/Users/arkadyvasilenko/spark-2.4.5-bin-hadoop2.7' # Set your own\n",
    "java8_location = '/library/java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home' # Set your own\n",
    "os.environ['JAVA_HOME'] = java8_location\n",
    "findspark.init(spark_home = spark_location) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.4.5\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.7.4 (default, Aug 13 2019 15:17:50)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "exec(open(os.path.join(\"/usr/local/Cellar/apache-spark/2.4.5/libexec/python/pyspark/shell.py\")).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()\n",
    "hive = HiveContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pays = spark.read.csv('../okved_test/data/pays.csv',inferSchema = True, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pays = pays.withColumn(\"hash_inn_kt\", pays[\"hash_inn_kt\"].cast('string'))\n",
    "inns = pays.select('hash_inn_kt').distinct().rdd.map(lambda r: r[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = pays.groupby('hash_inn_kt').agg(collect_list('hash_inn_dt').alias(\"hash_inn_dt\"))\n",
    "train_inn = grouped_df.select('hash_inn_dt').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_list = []\n",
    "for row in train_inn:\n",
    "    str_list.append(\" \".join(str(x) for x in row.hash_inn_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count_inn = 100\n",
    "vec_size = 5\n",
    "\n",
    "localDoc = [\",\".join(str(x) for x in str_list[:count_inn])]\n",
    "doc = sc.parallelize(localDoc).map(lambda line: line.split(\" \"))\n",
    "word2vec = Word2Vec()\n",
    "\n",
    "#params\n",
    "word2vec.setVectorSize(vec_size)\n",
    "#word2vec.setNumIterations(10)\n",
    "#word2vec.setNumPartitions(10)\n",
    "\n",
    "model = word2vec.fit(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectors to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_ = model.getVectors()\n",
    "vectors = {k: list([x for x in vectors_.get(k)])\n",
    "    for k in vectors_.keys()}\n",
    "\n",
    "embed_df = pd.DataFrame(data=vectors).T\n",
    "embed_df.columns = ['col' + str(i) for i in range(1, vec_size + 1)]\n",
    "\n",
    "embed_df['hash_inn'] = embed_df.index.astype('int')\n",
    "embed_df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get okved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_df = pd.read_csv('../data/inn_info_public.csv')\n",
    "private_df = pd.read_csv('../data/inn_info_private.csv')\n",
    "full = pd.concat([public_df.loc[public_df.okved2 != -1], private_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash_inn</th>\n",
       "      <th>okved2</th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3736</td>\n",
       "      <td>34</td>\n",
       "      <td>0.392305</td>\n",
       "      <td>-0.157705</td>\n",
       "      <td>-0.350331</td>\n",
       "      <td>-0.431061</td>\n",
       "      <td>-0.012637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>204639</td>\n",
       "      <td>34</td>\n",
       "      <td>0.176783</td>\n",
       "      <td>-1.020083</td>\n",
       "      <td>-0.350738</td>\n",
       "      <td>0.179880</td>\n",
       "      <td>0.839318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>123551</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.376219</td>\n",
       "      <td>-0.931577</td>\n",
       "      <td>-1.532010</td>\n",
       "      <td>0.414244</td>\n",
       "      <td>0.365705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>257788</td>\n",
       "      <td>12</td>\n",
       "      <td>0.439426</td>\n",
       "      <td>-0.296783</td>\n",
       "      <td>-0.072623</td>\n",
       "      <td>0.383588</td>\n",
       "      <td>0.000540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>113791</td>\n",
       "      <td>34</td>\n",
       "      <td>1.027697</td>\n",
       "      <td>0.781429</td>\n",
       "      <td>-0.198442</td>\n",
       "      <td>-0.027294</td>\n",
       "      <td>0.053618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hash_inn  okved2      col1      col2      col3      col4      col5\n",
       "0      3736      34  0.392305 -0.157705 -0.350331 -0.431061 -0.012637\n",
       "1    204639      34  0.176783 -1.020083 -0.350738  0.179880  0.839318\n",
       "2    123551      14 -0.376219 -0.931577 -1.532010  0.414244  0.365705\n",
       "3    257788      12  0.439426 -0.296783 -0.072623  0.383588  0.000540\n",
       "4    113791      34  1.027697  0.781429 -0.198442 -0.027294  0.053618"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = full[['hash_inn','okved2']].merge(embed_df, left_on='hash_inn', right_on='hash_inn')\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
