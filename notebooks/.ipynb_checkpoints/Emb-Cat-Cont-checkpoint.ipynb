{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from numpy import vstack\n",
    "from numpy import argmax\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Softmax\n",
    "from torch.nn import Module\n",
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "from torch.nn.init import xavier_uniform_\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as torch_optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-80b768b50529>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtab_embeddings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTabularDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFeedForwardNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'model'"
     ]
    }
   ],
   "source": [
    "from model.tab_embeddings import TabularDataset, FeedForwardNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/korniltsevdmitry/Desktop/python/projects/sber_walet_similar_companies/release/pyspark/ML360_SIMILAR_COMPANIES/notebooks'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('./data/result_df.csv', nrows=2000)\n",
    "data = pd.read_csv('../data/result_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash_inn</th>\n",
       "      <th>okved2</th>\n",
       "      <th>region</th>\n",
       "      <th>0_count_kt</th>\n",
       "      <th>1_count_kt</th>\n",
       "      <th>10_count_kt</th>\n",
       "      <th>1000_count_kt</th>\n",
       "      <th>11_count_kt</th>\n",
       "      <th>12_count_kt</th>\n",
       "      <th>13_count_kt</th>\n",
       "      <th>...</th>\n",
       "      <th>share_72_dt_dt</th>\n",
       "      <th>share_73_dt_dt</th>\n",
       "      <th>share_74_dt_dt</th>\n",
       "      <th>share_75_dt_dt</th>\n",
       "      <th>share_76_dt_dt</th>\n",
       "      <th>share_77_dt_dt</th>\n",
       "      <th>share_78_dt_dt</th>\n",
       "      <th>share_79_dt_dt</th>\n",
       "      <th>share_8_dt_dt</th>\n",
       "      <th>share_9_dt_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61058</td>\n",
       "      <td>34</td>\n",
       "      <td>86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8311</td>\n",
       "      <td>18</td>\n",
       "      <td>86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 331 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   hash_inn  okved2  region  0_count_kt  1_count_kt  10_count_kt  \\\n",
       "0     61058      34      86         NaN         NaN          NaN   \n",
       "1      8311      18      86         NaN         NaN          NaN   \n",
       "\n",
       "   1000_count_kt  11_count_kt  12_count_kt  13_count_kt  ...  share_72_dt_dt  \\\n",
       "0            NaN          NaN          NaN          NaN  ...             NaN   \n",
       "1            NaN          NaN          NaN          NaN  ...             NaN   \n",
       "\n",
       "   share_73_dt_dt  share_74_dt_dt  share_75_dt_dt  share_76_dt_dt  \\\n",
       "0             NaN             NaN             NaN             NaN   \n",
       "1             NaN             NaN             NaN             NaN   \n",
       "\n",
       "   share_77_dt_dt  share_78_dt_dt  share_79_dt_dt  share_8_dt_dt  \\\n",
       "0             NaN             NaN             NaN            NaN   \n",
       "1             NaN             NaN             NaN            NaN   \n",
       "\n",
       "   share_9_dt_dt  \n",
       "0            NaN  \n",
       "1            NaN  \n",
       "\n",
       "[2 rows x 331 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col = [\"region\"]\n",
    "cont_col = [col for col in data.columns if 'share' in col]\n",
    "target_col = [\"okved2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[cont_col + cat_col + target_col]\n",
    "data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.okved2.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>share_0_kt</th>\n",
       "      <th>share_1_kt</th>\n",
       "      <th>share_10_kt</th>\n",
       "      <th>share_1000_kt</th>\n",
       "      <th>share_11_kt</th>\n",
       "      <th>share_12_kt</th>\n",
       "      <th>share_13_kt</th>\n",
       "      <th>share_14_kt</th>\n",
       "      <th>share_15_kt</th>\n",
       "      <th>share_16_kt</th>\n",
       "      <th>...</th>\n",
       "      <th>share_74_dt_dt</th>\n",
       "      <th>share_75_dt_dt</th>\n",
       "      <th>share_76_dt_dt</th>\n",
       "      <th>share_77_dt_dt</th>\n",
       "      <th>share_78_dt_dt</th>\n",
       "      <th>share_79_dt_dt</th>\n",
       "      <th>share_8_dt_dt</th>\n",
       "      <th>share_9_dt_dt</th>\n",
       "      <th>region</th>\n",
       "      <th>okved2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 164 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   share_0_kt  share_1_kt  share_10_kt  share_1000_kt  share_11_kt  \\\n",
       "0         0.0         0.0          0.0            0.0          0.0   \n",
       "1         0.0         0.0          0.0            0.0          0.0   \n",
       "\n",
       "   share_12_kt  share_13_kt  share_14_kt  share_15_kt  share_16_kt  ...  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0  ...   \n",
       "1          0.0          0.0          0.0          0.0          0.0  ...   \n",
       "\n",
       "   share_74_dt_dt  share_75_dt_dt  share_76_dt_dt  share_77_dt_dt  \\\n",
       "0             0.0             0.0             0.0             0.0   \n",
       "1             0.0             0.0             0.0             0.0   \n",
       "\n",
       "   share_78_dt_dt  share_79_dt_dt  share_8_dt_dt  share_9_dt_dt  region  \\\n",
       "0             0.0             0.0            0.0            0.0      86   \n",
       "1             0.0             0.0            0.0            0.0      86   \n",
       "\n",
       "   okved2  \n",
       "0      34  \n",
       "1      18  \n",
       "\n",
       "[2 rows x 164 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoders = {}\n",
    "for col in cat_col:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    data[col] = label_encoders[col].fit_transform(data[col]) \n",
    "    data[col] = data[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "Y = LabelEncoder().fit_transform(data[target_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[cont_col + cat_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_cols_dict = {n: len(col.cat.categories) for n, col in X[cat_col].items() if len(col.cat.categories) > 2}\n",
    "emb_cols = emb_cols_dict.keys()\n",
    "emb_sizes = [(c, min(50, (c+1)//2)) for _,c in emb_cols_dict.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(91, 46)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>share_0_kt</th>\n",
       "      <th>share_1_kt</th>\n",
       "      <th>share_10_kt</th>\n",
       "      <th>share_1000_kt</th>\n",
       "      <th>share_11_kt</th>\n",
       "      <th>share_12_kt</th>\n",
       "      <th>share_13_kt</th>\n",
       "      <th>share_14_kt</th>\n",
       "      <th>share_15_kt</th>\n",
       "      <th>share_16_kt</th>\n",
       "      <th>...</th>\n",
       "      <th>share_73_dt_dt</th>\n",
       "      <th>share_74_dt_dt</th>\n",
       "      <th>share_75_dt_dt</th>\n",
       "      <th>share_76_dt_dt</th>\n",
       "      <th>share_77_dt_dt</th>\n",
       "      <th>share_78_dt_dt</th>\n",
       "      <th>share_79_dt_dt</th>\n",
       "      <th>share_8_dt_dt</th>\n",
       "      <th>share_9_dt_dt</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149412</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158476</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 163 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        share_0_kt  share_1_kt  share_10_kt  share_1000_kt  share_11_kt  \\\n",
       "149412         0.0         0.0          0.0            0.0          0.0   \n",
       "158476         0.0         0.0          0.0            0.0          0.0   \n",
       "\n",
       "        share_12_kt  share_13_kt  share_14_kt  share_15_kt  share_16_kt  ...  \\\n",
       "149412          0.0          0.0          0.0          0.0          0.0  ...   \n",
       "158476          0.0          0.0          0.0          0.0          0.0  ...   \n",
       "\n",
       "        share_73_dt_dt  share_74_dt_dt  share_75_dt_dt  share_76_dt_dt  \\\n",
       "149412             0.0             0.0             0.0             0.0   \n",
       "158476             0.0             0.0             0.0             0.0   \n",
       "\n",
       "        share_77_dt_dt  share_78_dt_dt  share_79_dt_dt  share_8_dt_dt  \\\n",
       "149412             0.0             0.0             0.0            0.0   \n",
       "158476             0.0             0.0             0.0            0.0   \n",
       "\n",
       "        share_9_dt_dt  region  \n",
       "149412            0.0      24  \n",
       "158476            0.0      81  \n",
       "\n",
       "[2 rows x 163 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShelterOutcomeDataset(Dataset):\n",
    "    def __init__(self, X, Y, emb_cols):\n",
    "        X = X.copy()\n",
    "        #categorical columns\n",
    "        self.X1 = X.loc[:, emb_cols].copy().values.astype(np.int64)\n",
    "        #numerical columns\n",
    "        self.X2 = X.drop(columns=emb_cols).copy().values.astype(np.float32)\n",
    "        self.y = Y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X1[idx], self.X2[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating train and valid datasets\n",
    "train_ds = ShelterOutcomeDataset(X_train, y_train, emb_cols)\n",
    "valid_ds = ShelterOutcomeDataset(X_val, y_val, emb_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShelterOutcomeModel(nn.Module):\n",
    "    def __init__(self, embedding_sizes, n_cont):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.ModuleList([nn.Embedding(categories, size) for categories,size in embedding_sizes])\n",
    "        n_emb = sum(e.embedding_dim for e in self.embeddings) #length of all embeddings combined\n",
    "        self.n_emb, self.n_cont = n_emb, n_cont\n",
    "        self.lin1 = nn.Linear(self.n_emb + self.n_cont, 800)\n",
    "        self.lin2 = nn.Linear(800, 280)\n",
    "        self.lin3 = nn.Linear(280, 75)\n",
    "        self.bn1 = nn.BatchNorm1d(self.n_cont)\n",
    "        self.bn2 = nn.BatchNorm1d(800)\n",
    "        self.bn3 = nn.BatchNorm1d(280)\n",
    "        self.emb_drop = nn.Dropout(0.6)\n",
    "        self.drops = nn.Dropout(0.3)\n",
    "        \n",
    "\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        x = [e(x_cat[:,i]) for i,e in enumerate(self.embeddings)]\n",
    "        x = torch.cat(x, 1)\n",
    "        x = self.emb_drop(x)\n",
    "        x2 = self.bn1(x_cont)\n",
    "        x = torch.cat([x, x2], 1)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.drops(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = self.drops(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.lin3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cont_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShelterOutcomeModel(\n",
       "  (embeddings): ModuleList(\n",
       "    (0): Embedding(77, 39)\n",
       "  )\n",
       "  (lin1): Linear(in_features=201, out_features=800, bias=True)\n",
       "  (lin2): Linear(in_features=800, out_features=280, bias=True)\n",
       "  (lin3): Linear(in_features=280, out_features=75, bias=True)\n",
       "  (bn1): BatchNorm1d(162, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2): BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn3): BatchNorm1d(280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (emb_drop): Dropout(p=0.6, inplace=False)\n",
       "  (drops): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ShelterOutcomeModel(embedding_sizes=emb_sizes, n_cont=len(cont_col))\n",
    "to_device(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, lr = 0.001, wd = 0.0):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optim = torch_optim.Adam(parameters, lr=lr, weight_decay=wd)\n",
    "    return optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optim, train_dl):\n",
    "    model.train()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    for x1, x2, y in train_dl:\n",
    "        batch = y.shape[0]\n",
    "        output = model(x1, x2)\n",
    "        loss = F.cross_entropy(output, y)   \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        total += batch\n",
    "        sum_loss += batch*(loss.item())\n",
    "    return sum_loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_loss(model, valid_dl):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    correct = 0\n",
    "    predictions, actuals = list(), list()\n",
    "    for x1, x2, y in valid_dl:\n",
    "        current_batch_size = y.shape[0]\n",
    "        out = model(x1, x2)\n",
    "        loss = F.cross_entropy(out, y)\n",
    "        sum_loss += current_batch_size*(loss.item())\n",
    "        total += current_batch_size\n",
    "        pred = torch.max(out, 1)[1]\n",
    "        correct += (pred == y).float().sum().item()\n",
    "        \n",
    "        y = y.reshape((len(y), 1))\n",
    "        pred = pred.reshape((len(pred), 1))\n",
    "        # store\n",
    "        predictions.append(pred)\n",
    "        actuals.append(y)\n",
    "    print(len(predictions), len(actuals))\n",
    "    print(\"valid loss %.3f and accuracy %.3f\" % (sum_loss/total, correct/total))\n",
    "    predictions, actuals = vstack(predictions), vstack(actuals)\n",
    "    return actuals, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(test_dl, model):\n",
    "    predictions, actuals = list(), list()\n",
    "    for i, (inputs, targets) in enumerate(test_dl):\n",
    "        yhat = model(inputs)\n",
    "        yhat = yhat.detach().numpy()\n",
    "        actual = targets.numpy()\n",
    "        yhat = argmax(yhat, axis=1)\n",
    "        # reshape for stacking\n",
    "        actual = actual.reshape((len(actual), 1))\n",
    "        yhat = yhat.reshape((len(yhat), 1))\n",
    "        # store\n",
    "        predictions.append(yhat)\n",
    "        actuals.append(actual)\n",
    "    predictions, actuals = vstack(predictions), vstack(actuals)   \n",
    "    return actuals, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, epochs, lr=0.01, wd=0.0):\n",
    "    optim = get_optimizer(model, lr = lr, wd = wd)\n",
    "    for i in range(epochs): \n",
    "        loss = train_model(model, optim, train_dl)\n",
    "        print(\"training loss: \", loss)\n",
    "        actuals, predictions = val_loss(model, valid_dl)\n",
    "    return actuals, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss:  1.574555064671075\n",
      "3 3\n",
      "valid loss 7.568 and accuracy 0.217\n",
      "training loss:  1.6045985232538251\n",
      "3 3\n",
      "valid loss 6.694 and accuracy 0.215\n",
      "training loss:  1.4234748790513223\n",
      "3 3\n",
      "valid loss 6.620 and accuracy 0.191\n",
      "training loss:  1.3651253376434098\n",
      "3 3\n",
      "valid loss 6.876 and accuracy 0.229\n",
      "training loss:  1.2920929342953127\n",
      "3 3\n",
      "valid loss 7.513 and accuracy 0.227\n",
      "training loss:  1.1697089661413165\n",
      "3 3\n",
      "valid loss 7.624 and accuracy 0.215\n",
      "training loss:  1.1109754711834352\n",
      "3 3\n",
      "valid loss 7.391 and accuracy 0.224\n",
      "training loss:  1.1432709775753875\n",
      "3 3\n",
      "valid loss 7.045 and accuracy 0.211\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         4\n",
      "           3       0.28      0.24      0.26        33\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.33      0.22      0.27         9\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.06      0.04      0.05        23\n",
      "           8       0.00      0.00      0.00         7\n",
      "           9       0.00      0.00      0.00         3\n",
      "          10       0.17      0.12      0.14        17\n",
      "          11       0.40      0.44      0.42       188\n",
      "          12       0.46      0.37      0.41        35\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       0.00      0.00      0.00         4\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         7\n",
      "          17       0.00      0.00      0.00         2\n",
      "          18       0.00      0.00      0.00         1\n",
      "          19       0.25      0.22      0.24         9\n",
      "          20       0.00      0.00      0.00         8\n",
      "          21       0.00      0.00      0.00         6\n",
      "          22       0.00      0.00      0.00         1\n",
      "          23       0.00      0.00      0.00         1\n",
      "          24       0.21      0.21      0.21        14\n",
      "          25       0.00      0.00      0.00         1\n",
      "          27       0.00      0.00      0.00         7\n",
      "          28       0.00      0.00      0.00         6\n",
      "          29       0.00      0.00      0.00         1\n",
      "          30       0.00      0.00      0.00         5\n",
      "          31       0.00      0.00      0.00         2\n",
      "          32       0.29      0.25      0.27        51\n",
      "          36       0.00      0.00      0.00         3\n",
      "          37       0.17      0.07      0.10        14\n",
      "          39       0.00      0.00      0.00         3\n",
      "          40       0.00      0.00      0.00         2\n",
      "          41       0.00      0.00      0.00         5\n",
      "          42       0.25      0.33      0.29         3\n",
      "          44       0.07      0.08      0.08        12\n",
      "          45       0.00      0.00      0.00         5\n",
      "          46       0.10      0.10      0.10        10\n",
      "          47       0.00      0.00      0.00         5\n",
      "          48       0.00      0.00      0.00         1\n",
      "          49       0.12      0.19      0.15        26\n",
      "          50       0.33      0.50      0.40         4\n",
      "          51       0.00      0.00      0.00         3\n",
      "          52       0.00      0.00      0.00        20\n",
      "          53       0.00      0.00      0.00         8\n",
      "          54       0.00      0.00      0.00         1\n",
      "          55       0.00      0.00      0.00         2\n",
      "          56       0.00      0.00      0.00         6\n",
      "          57       0.00      0.00      0.00         6\n",
      "          58       0.00      0.00      0.00        12\n",
      "          59       0.05      0.09      0.06        11\n",
      "          60       0.00      0.00      0.00         1\n",
      "          61       0.00      0.00      0.00         4\n",
      "          62       0.00      0.00      0.00         4\n",
      "          63       0.00      0.00      0.00         0\n",
      "          64       0.00      0.00      0.00         4\n",
      "          65       0.00      0.00      0.00         2\n",
      "          66       0.00      0.00      0.00         0\n",
      "          67       0.00      0.00      0.00         2\n",
      "          68       0.00      0.00      0.00         5\n",
      "          69       0.00      0.00      0.00        10\n",
      "          71       0.00      0.00      0.00         5\n",
      "          72       0.00      0.00      0.00         3\n",
      "          73       0.00      0.00      0.00         2\n",
      "          74       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.21       660\n",
      "   macro avg       0.05      0.05      0.05       660\n",
      "weighted avg       0.21      0.21      0.21       660\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "actuals, predictions = train_loop(model, epochs=8, lr=0.05, wd=0.00001)\n",
    "print(classification_report(actuals, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
