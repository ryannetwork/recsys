{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import rand as sprand\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Make up some random explicit feedback ratings\n",
    "# and convert to a numpy array\n",
    "n_users = 1000\n",
    "n_items = 1000\n",
    "ratings = sprand(n_users, n_items, \n",
    "                 density=0.01, format='csr')\n",
    "ratings.data = (np.random.randint(1, 5, \n",
    "                                  size=ratings.nnz)\n",
    "                          .astype(np.float64))\n",
    "ratings = ratings.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n_users, n_items, n_factors=20):\n",
    "        super().__init__()\n",
    "        self.user_factors = torch.nn.Embedding(n_users, \n",
    "                                               n_factors,\n",
    "                                               sparse=True)\n",
    "        self.item_factors = torch.nn.Embedding(n_items, \n",
    "                                               n_factors,\n",
    "                                               sparse=True)\n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        return (self.user_factors(user) * self.item_factors(item)).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MatrixFactorization(n_users, n_items, n_factors=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.SGD(model.parameters(), \n",
    "#                             lr=1e-6) # learning rate\n",
    "\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 0 is 17.685449600219727\n",
      "loss on epoch 1 is 17.682336807250977\n",
      "loss on epoch 2 is 17.68018341064453\n"
     ]
    }
   ],
   "source": [
    "# Sort our data\n",
    "n_epochs= 3\n",
    "rows, cols = ratings.nonzero()\n",
    "p = np.random.permutation(len(rows))\n",
    "rows, cols = rows[p], cols[p]\n",
    "for epoch in range(n_epochs):\n",
    "    for row, col in zip(*(rows, cols)):\n",
    "        # Turn data into tensors\n",
    "        rating = torch.FloatTensor([ratings[row, col]])\n",
    "        row = torch.LongTensor([row])\n",
    "        col = torch.LongTensor([col])\n",
    "\n",
    "        # Predict and calculate loss\n",
    "        prediction = model(row, col)\n",
    "        loss = loss_func(prediction, rating)\n",
    "\n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "    print(f'loss on epoch {epoch} is {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _shuffle(interactions):\n",
    "\n",
    "#     users = interactions.row\n",
    "#     items = interactions.col\n",
    "#     ratings = interactions.data\n",
    "\n",
    "#     shuffle_indices = np.arange(len(users))\n",
    "#     np.random.shuffle(shuffle_indices)\n",
    "\n",
    "#     return (users[shuffle_indices].astype(np.int64),\n",
    "#             items[shuffle_indices].astype(np.int64),\n",
    "#             ratings[shuffle_indices].astype(np.float32))\n",
    "\n",
    "def _shuffle(interactions):\n",
    "\n",
    "    rows, cols = ratings.nonzero()\n",
    "    p = np.random.permutation(len(rows))\n",
    "    users, items = rows[p], cols[p]\n",
    "    ratings = ratings.nonzero()\n",
    "\n",
    "    return (users.astype(np.int64),\n",
    "            items.astype(np.int64),\n",
    "            ratings.astype(np.float32))\n",
    "\n",
    "def _gpu(tensor, gpu=False):\n",
    "\n",
    "    if gpu:\n",
    "        return tensor.cuda()\n",
    "    else:\n",
    "        return tensor\n",
    "\n",
    "\n",
    "def _cpu(tensor):\n",
    "\n",
    "    if tensor.is_cuda:\n",
    "        return tensor.cpu()\n",
    "    else:\n",
    "        return tensor\n",
    "\n",
    "\n",
    "def _minibatch(tensor, batch_size):\n",
    "\n",
    "    for i in range(0, len(tensor), batch_size):\n",
    "        yield tensor[i:i + batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = ratings.nonzero()\n",
    "p = np.random.permutation(len(rows))\n",
    "rows, cols = rows[p], cols[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5596, 2780, 9537, ..., 6526, 6244, 7791])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = sprand(n_users, n_items, \n",
    "                 density=0.01, format='csr')\n",
    "ratings.data = (np.random.randint(1, 5, \n",
    "                                  size=ratings.nnz)\n",
    "                          .astype(np.float64))\n",
    "ratings = ratings.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-0e3294c279b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pointwise_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratings_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-6a82f6b7c313>\u001b[0m in \u001b[0;36m_pointwise_loss\u001b[0;34m(users, items, ratings)\u001b[0m\n\u001b[1;32m      9\u001b[0m     )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mpositives_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mnegatives_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegatives\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "_batch_size = 64\n",
    "_num_users = None\n",
    "_num_items = 5\n",
    "_net = None\n",
    "_use_cuda = False\n",
    "for epoch_num in range(n_epochs):\n",
    "\n",
    "    rows, cols = ratings.nonzero()\n",
    "    p = np.random.permutation(len(rows))\n",
    "    users, items = rows[p], cols[p]\n",
    "    ratings = ratings.nonzero()\n",
    "    ratings = np.asarray(ratings)\n",
    "\n",
    "    user_ids_tensor = _cpu(torch.from_numpy(users)\n",
    "                          )\n",
    "    item_ids_tensor = _cpu(torch.from_numpy(items))\n",
    "    ratings_tensor = _cpu(torch.from_numpy(ratings)\n",
    "                         )\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for (batch_user,\n",
    "         batch_item,\n",
    "         batch_ratings) in zip(_minibatch(user_ids_tensor,\n",
    "                                          _batch_size),\n",
    "                               _minibatch(item_ids_tensor,\n",
    "                                          _batch_size),\n",
    "                               _minibatch(ratings_tensor,\n",
    "                                          _batch_size)):\n",
    "\n",
    "        user_var = Variable(batch_user)\n",
    "        item_var = Variable(batch_item)\n",
    "        ratings_var = Variable(batch_ratings)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = _pointwise_loss(user_var, item_var, ratings_var)\n",
    "        epoch_loss += loss.data[0]\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if verbose:\n",
    "        print('Epoch {}: loss {}'.format(epoch_num, epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pointwise_loss(users, items, ratings):\n",
    "\n",
    "    negatives = Variable(\n",
    "        _gpu(\n",
    "            torch.from_numpy(np.random.randint(0,\n",
    "                                               _num_items,\n",
    "                                               len(users))),\n",
    "            _use_cuda)\n",
    "    )\n",
    "\n",
    "    positives_loss = (1.0 - F.sigmoid(_net(users, items)))\n",
    "    negatives_loss = F.sigmoid(_net(users, negatives))\n",
    "\n",
    "    return torch.cat([positives_loss, negatives_loss]).mean()\n",
    "\n",
    "# def _bpr_loss(self, users, items, ratings):\n",
    "\n",
    "#     negatives = Variable(\n",
    "#         _gpu(\n",
    "#             torch.from_numpy(np.random.randint(0,\n",
    "#                                                self._num_items,\n",
    "#                                                len(users))),\n",
    "#             self._use_cuda)\n",
    "#     )\n",
    "\n",
    "#     return (1.0 - F.sigmoid(self._net(users, items) -\n",
    "#                             self._net(users, negatives))).mean()\n",
    "\n",
    "# def _adaptive_loss(self, users, items, ratings,\n",
    "#     n_neg_candidates=5):\n",
    "#     negatives = Variable(\n",
    "#         _gpu(\n",
    "#             torch.from_numpy(\n",
    "#                 np.random.randint(0, self._num_items,\n",
    "#                     (len(users), n_neg_candidates))),\n",
    "#             self._use_cuda)\n",
    "#     )\n",
    "#     negative_predictions = self._net(\n",
    "#         users.repeat(n_neg_candidates, 1).transpose_(0,1),\n",
    "#         negatives\n",
    "#         ).view(-1, n_neg_candidates)\n",
    "\n",
    "#     best_negative_prediction, _ = negative_predictions.max(1)\n",
    "#     positive_prediction = self._net(users, items)\n",
    "\n",
    "#     return torch.mean(torch.clamp(best_negative_prediction -\n",
    "#                                   positive_prediction\n",
    "#                                   + 1.0, 0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic matrix factorization model without bias term\n",
    "class Recommender(nn.Module):\n",
    "    def __init__(self, num_users, num_artists, num_factors):\n",
    "        super().__init__()\n",
    "        self.u = nn.Embedding(num_users, num_factors)\n",
    "        self.a = nn.Embedding(num_artists, num_factors)\n",
    "        self.u.weight.data.uniform_(-.01, .01)\n",
    "        self.a.weight.data.uniform_(-.01, .01)\n",
    "\n",
    "    def forward(self, cats, conts):\n",
    "        users, artists = cats[:,0], cats[:,1]\n",
    "        us, art = self.u(users), self.a(artists)\n",
    "        return (us*art).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiasedMatrixFactorization(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n_users, n_items, n_factors=20):\n",
    "        super().__init__()\n",
    "        self.user_factors = torch.nn.Embedding(n_users, \n",
    "                                               n_factors,\n",
    "                                               sparse=True)\n",
    "        self.item_factors = torch.nn.Embedding(n_items, \n",
    "                                               n_factors,\n",
    "                                               sparse=True)\n",
    "        self.user_biases = torch.nn.Embedding(n_users, \n",
    "                                              1,\n",
    "                                              sparse=True)\n",
    "        self.item_biases = torch.nn.Embedding(n_items,\n",
    "                                              1,\n",
    "                                              sparse=True)\n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        pred = self.user_biases(user) + self.item_biases(item)\n",
    "        pred += (self.user_factors(user) * self.item_factors(item)).sum(dim=1, keepdim=True)\n",
    "        return pred.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class MatrixFactorization(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n_users, n_items, n_factors=20):\n",
    "        super().__init__()\n",
    "        self.user_factors = nn.Embedding(n_users, n_factors, sparse=True)\n",
    "        self.item_factors = nn.Embedding(n_users, n_factors, sparse=True)\n",
    "        self.user_biases = nn.Embedding(n_users, 1, sparse=True)\n",
    "        self.item_biases = nn.Embedding((n_users, 1, sparse=True)\n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        dot = (self.user_factors(user) * self.item_factors(item)).sum(dim=1, keepdim=True)\n",
    "        bias = self.user_biases(user) + self.item_biases(item)\n",
    "        return dot + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_loss_func = torch.optim.SGD(model.parameters(), lr=1e-6,\n",
    "                                weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    lr: 1e-06\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 1e-05\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "adagrad_loss = torch.optim.Adagrad(model.parameters(), lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adagrad (\n",
       "Parameter Group 0\n",
       "    eps: 1e-10\n",
       "    initial_accumulator_value: 0\n",
       "    lr: 1e-06\n",
       "    lr_decay: 0\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adagrad_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
